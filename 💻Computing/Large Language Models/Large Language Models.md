[ðŸ“ Explore](obsidian://open?vault=Saarthak's_Headspace&file=ðŸ“%20Explore) > Large Language Models

---
- A neural network basically tries to predict the next word in a given sequence of words
## Stages of Training a model
1. Pre-training
	- Produces a document generator 
	- High hallucinations 
2. Fine tuning
	- Produces an asistant model
	- Requires labeled information 
	- Aligns the output of model in the correct direction
3. Optional more fine tuning
	- Uses comparison of multiple generated outputs to fine tune the model
## Components 
A large language model just has two files
1. Parameters 
    -  Weights/Parameters of the neural network 
    - Can be as large as hundreds of GBs
    - Created during the training phase of model
    - Raw data â†’ Training â†’ Compiled parameters for the model (lossy compressed raw data)
    - Extremely computationally demanding and expensive process
2. Code for running
	- Computationally cheap process
---
# References
1. \[1hr Talk] Intro to Large Language Models - https://www.youtube.com/watch?v=zjkBMFhNj_g
# Tags
#incomplete